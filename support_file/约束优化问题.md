约束优化问题的一般形式如下：

$ \begin{aligned}
\min \quad & f(x) \\
\text{s.t.} \quad & g_i(x) \leq 0 \\
& h_j(x)=0
\end{aligned} $

其中，$ x \in R_n $，$ g_i(x)  $代表不等式约束， $ h_j(x)  $代表等式约束，下标代表约束的个数。

在众多类型的约束优化问题中，有几类问题目前得到了较为广泛的研究，取得了不错的结果。其中包括了：

+ 线性规划（Linear Programming，LP）:

$ \begin{aligned}
\min \quad & c^Tx+d \\
\text{s.t.} \quad & Ax \leq b \\
& G x = h
\end{aligned} $

![](https://cdn.nlark.com/yuque/0/2025/png/22737080/1737010576934-af4138aa-4b09-4cab-9df9-6e2972d70cdc.png)

线性规划的时间复杂度为$ O((m+n)^{3/2}n^2L) $，其中，m 为约束的数量，n 为决策变量的维度，L 为精确数字

+ 二次规划（Quadratic Programming，QP）: 

$ \begin{aligned}
\min \quad & \frac{1}{2} x^T Q x + p^T x \\
\text{s.t.} \quad & A x \leq b \\
& G x = h
\end{aligned} $

![](https://cdn.nlark.com/yuque/0/2025/png/22737080/1737035225095-1d4dae67-9507-4a36-bac3-d62a4e4d89fd.png)

+ 二阶锥规划（Second-Order Conic Programming，SOCP）二阶锥规划的一般形式： 

$ \begin{aligned}
\min \quad & f^Tx  \\
\text{s.t.} \quad & ||A_ix+b_i||_2≤c_i^Tx+d_i \\
& Gx = h
\end{aligned} $

![](https://cdn.nlark.com/yuque/0/2025/png/22737080/1737010620692-6d42be68-9e43-44a6-b5a2-7982c1b0a7f2.png)

时间复杂度为$ O(m^{1/2}n(mn+n^2+\sum_i k_i)L) $，其中，m 为约束的数量，n 为决策变量的维度，L 为精确数字，k 为锥体的维度。

+ 半定规划（Semi-Definite Programming，SDP）

$ \begin{aligned}
\min \quad & c^T x \\
\text{s.t.} \quad & x_1 A_1^i + \dots + x_n A_n^i + B^i \preceq 0 \\
& Gx = h
\end{aligned} $

![](https://cdn.nlark.com/yuque/0/2025/png/22737080/1737010699604-1b04430e-5cf2-4534-9668-7eccec8b4e41.png)

时间复杂度为$ O(\sqrt{\sum_ik_i}n(n^2+n\sum_ik_i+\sum k_i^3))L) $，其中，m 为约束的数量，n 为决策变量的维度，L 为精确数字，k 为锥体的维度。

 一般来说，上述四类优化问题存在如下关系：**线性规划**⊆**二次规划**⊆**二阶锥规划**⊆**半定规划⊆ 约束优化问题。**

![](https://cdn.nlark.com/yuque/0/2025/png/22737080/1737010501906-7fb202b3-e387-4ac2-8bdc-36424efe3659.png)

# 1 线性规划算法
解决一般的线性规划问题的通用算法很多，例如：单纯形法、内点法(

[07-内点法(不等式约束优化算法) - B站-水论文的程序猿 - 博客园](https://www.cnblogs.com/nickchen121/p/14922860.html)

)等等。然而，在机器人领域，常常会面临一些优化变量维度很低，但是约束数量很多的优化问题。针对这类优化问题找到高效的求解方法对于机器人应用来说非常重要。

举个例子，给定一个凸多面体 $ P={x|A_ix+b_i≤0}  $，想要在凸多面体的内部找到一个点，使得它距离凸多面体各个平面的安全距离最大？这个问题可以建模为，定义优化变量为 $ x \in R_n,t\in R $ ，然后求解优化问题： 

$ \max_{x,t}t, \text{s.t.} A_ix+b_i+t≤0 $ 

这个优化问题中，优化变量的维度是 $ n+1 $，通常三维环境中这个维度就是4，然而，$  i  $的取值可能非常大，也就是凸多面体的面数很多，约束数量很大。

针对这类问题，课程中提出了一类Seidel's算法进行求解。这个算法的核心思想是分成两个步骤：

+ 逐个加入线性约束，判断当前的最优解是否满足新加入的线性约束，满足的话则继续添加下一个约束，不满足的话就去计算基于当前已加入的约束条件下，新的最优解。
+ 计算新的最优解的方式是：把所有已加入的约束投影到新加入的约束超平面上（因为最优解一定在新加入约束超平面内），这样优化问题的维数会降低1维，然后求解这个降维后的问题即可。总的来说，Seidel's方法基于两个思想，一个是逐步添加约束，另一个是利用递归思想把高维优化问题降维求解。具体的计算方法可Google搜索：Seidel’s LP algorithm。

Seidel’s算法通常的时间复杂度为 $ O(n!m)  $，其中， n 是优化变量的维数， m 是约束的个数，当 n 取值较小时，可以认为Seidel’s的时间复杂度就是 $ O(m) $ ，也就是和约束的个数成线性复杂度。因此，采用Seidel’s算法求解低维多约束的线性规划问题是非常高效的。

# 2 二次规划算法
通用的求解二次规划问题的算法和求解器也非常多。然而，对于机器人领域中常见的低维多约束问题，本课程中也介绍了一种Seidel's算法的二次规划推广版本。这个算法的时间复杂度也是 O(n!m) ，其中， n 是优化变量的维数， m 是约束的个数。这个算法应该是汪博自己推广得到的，没有找到对应的文章，具体的计算方法可以参考本课程讲义。

# 3 一般约束优化问题转换为无约束优化问题的方法
前面阐述的是一些约束优化问题的特例，比如低维多约束的线性规划、二次规划问题。对于一般的约束优化问题，有一些将其转换为无约束优化问题的方法，就可以采用无约束优化算法进行求解。

## 3.1 罚函数法
**罚函数法的核心思想是把违反约束的程度转换为一种惩罚值，加入到目标函数中，当违反约束程度越大时，目标函数值就会越大，因此倾向于选取约束范围内的解。**允许当前解违背约束，这是罚函数法的一个特点。罚函数法适用于等式约束和不等式约束。

考虑带有等式约束的优化问题：

$ \begin{aligned}
    & \min_x f(x) \\
    & \text{s.t.} \quad c_i(x) = 0, \quad i \in E
\end{aligned}
 $

通过罚函数方法，将原问题转换为无约束优化问题： 

$ 
\min_x P_E(x, \sigma) = \min_x \left( f(x) + \frac{1}{2} \sigma \sum_i c_i^2(x) \right) $

随着 $ \sigma $ 不断增大，直至增大到正无穷，无约束优化问题的最优解会和原问题的最优解越来越接近。

考虑带有不等式约束的优化问题：

$ \begin{aligned}
    & \min_x f(x) \\
    & \text{s.t.} \quad c_i(x) \leq 0, \quad i \in \mathcal{I}
\end{aligned} $

通过罚函数方法，将原问题转换为无约束优化问题：

$ \min_x P_I(x, \sigma) = \min_x \left( f(x) + \frac{1}{2} \sigma \sum_{i} \max[c_i(x), 0]^2 \right) $

## 3.2 障碍函数法
**障碍物函数法主要针对不等式约束，主要思想是设置一道高墙，避免迭代过程中，迭代解跑出约束范围。**因此，在障碍函数法中是不允许当前解违背约束的，这与罚函数法有显著的区别。

考虑带有不等式约束的优化问题：

$ \begin{aligned}
    & \min_x f(x) \\
    & \text{s.t.} \quad c_i(x) \leq 0, \quad i \in \mathcal{I}
\end{aligned} $

通过障碍函数方法，将原问题转换为无约束优化问题：

（1）logarithmic barrier

$ \min_x B_{ln}(x,\sigma) = \min_xf(x)-\frac{1}{\sigma}\sum_i ln(-c_i(x)) $

（2）inverse barrier 

$ \min_x B_{inv}(x,\sigma) = \min_xf(x)-\frac{1}{\sigma}\sum_i \frac{1}{c_i(x)} $

（3）exponential barrier

$ \min_x B_{exp}(x,\sigma) = \min_xf(x)+\frac{1}{\sigma}\sum_i exp(-\frac{1}{c_i(x)}) $

当 $ \sigma $ 越来越接近0的时候，障碍函数趋近于无穷大，此时无约束优化问题的最优解和原问题的最优解基本完全一致。

## 3.3 拉格朗日松弛算法
考虑一个具有等式约束的凸优化问题，形式如下： 

$ \begin{aligned}
    & \min_x f(x) \\
    & \text{s.t.} Ax=b
\end{aligned} $

定义其Lagrange函数为： 

$ {L}(x, \lambda) = f(x) + \langle \lambda, Ax - b \rangle $

基于Lagrange函数的定义，原始问题可以转换为如下问题：$ \min_x\max_\lambda{L}(x, \lambda) $。可以对这个新的优化问题进行分析:

+ 当 $ Ax=b  $时， $ L(x,\lambda)=f(x) $ ，和 $ \lambda $ 无关，因此 $ \min_x\max_\lambda L(x,λ)=\min_xf(x)  $。
+ 当 $ Ax\neq b $ 时， $ \max_\lambda L(x,λ)= \max_\lambda( f(x) + \langle \lambda, Ax - b \rangle) = \infty $ ，因为 $ \lambda $ 可以任意取到正负无穷，由于我们要最小化这个拉格朗日函数，所以不可能让$ Ax\neq b $ 这种情况出现。

下面使用Uzawa's method 求解这个问题。

一般来说，对于 $ \min_x\max_\lambda L(x,λ)=f(x)+⟨λ,Ax−b⟩ $ 的优化问题， $ \max_\lambda L(x,\lambda)  $得到的最优解$  λ^∗(x) $ 不是一个关于 $ x $ 的连续函数（显然，当 $ Ax=b $ 和 $ Ax\neq b $ 时取值是完全不同的），这会导致在优化： $ \min_x L(x,λ^∗(x)) $ 的时候是非常困难的。然而，当 $ L(x,\lambda) $ 相对于 $ x $ 是严格凸函数的时候， 把minimize和maximum调换顺序后的优化问题，即$ \max_\lambda \min_xL(x,\lambda):=f(x)+⟨\lambda,Ax−b⟩ $ 这个问题会变得更加好求。因为， $ \min_xL(x,\lambda)  $得到的最优解 $ x^∗(λ) $ 是一个连续函数。此外，冯诺依曼提出了一个定理： $ \max_\lambda \min_x L(x,\lambda) \leq \min_x\max_\lambda L(x,λ)  $。并且，当 $ f(x) $ 是连续凸函数时，等号成立。因此，我们可以通过求解 $ \max_\lambda \min_x L(x,λ) $ 问题来求解原问题的最优解。具体方法为：

> 1. 优化 $ \min_xL(x,\lambda)  $问题，即求解$  x_{k+1}=\arg⁡\min_xL(x,\lambda_k) $
> 2. 优化 $ \max_\lambda d(\lambda):=f(x^∗(\lambda))+⟨\lambda,Ax^∗ (λ)−b⟩ $， 利用梯度下降（上升）法， 更新Lagrange乘子，$ \lambda_{k+1}=\lambda_k+\alpha(Ax_{k+1}−b) $
> 3. 随着迭代的进行，不断重复 $ x $ 和 $ \lambda $ 的更新，直至达到全局最优解。
>

# 4 增广拉格朗日方法
相比于前面介绍的罚函数法、障碍函数法、拉格朗日松弛方法，增广拉格朗日方法是一种更加成熟可靠的方法。罚函数法、障碍函数法随着 $ \lambda $ 的变化，最终的最优解附近的Hessian矩阵条件数会越来越大，性质越来越恶劣。拉格朗日松弛方法对目标函数有严格凸的假设，并且只考虑等式约束的情况。然而，增广拉格朗日方法是一种相对可靠的方法，能够应用于绝大多数的约束优化问题。

## 4.1 等式约束的处理
考虑一个具有等式约束的优化问题，形式如下：

$ \begin{aligned}
    & \min_xf(x) \\
    & \text{s.t.} h(x)=0 \\
\end{aligned} $

定义其Lagrange函数为： 

$ L(x, \lambda)=f(x)+\lambda^Th(x) $。

根据前文的介绍，原始问题可以转换为如下问题： $ \min_x\max_\lambda L(x,\lambda)  $。然而，对于 $ \max_\lambda f(x)+\lambda^T h(x) $ 这个优化问题，当 $ h(x) \neq 0  $时， $ \lambda $会取到无穷大，当 $ h(x)=0 $,$ \lambda $ 会取任意值。显然，这样得到的$  g(x)=\max_\lambda f(x)+\lambda^Th(x)  $函数是一个不连续的函数，外层优化极难进行。

**算法原理：**

在增广拉格朗日方法里，把原始问题进行了一定改造，加入了一个正则项，也就是对 $ \lambda $ 的取值进行约束，让 $ \lambda $ 围绕一个 $ \bar\lambda $ 进行变化，从而使得原问题变得连续。改造后的Lagrange函数如下：

$ \min_x\max_{\lambda} \left( f(x) + \lambda^T h(x) - \frac{1}{2\rho}  \| \lambda - \bar{\lambda} \|^2 \right) $

其中，$ \bar\lambda $ 是一个预先定义的先验值，$ \rho $是一个参数。

当然，这样的改造存在一个问题：由于改造过后的问题相比于原问题多了一项： $ \frac{1}{2\rho} \| \lambda - \bar{\lambda} \|^2 $，如何保证改造过后的优化问题和改造前的最优解一致呢？一般来说，有两种手段：

+ 增大$ \rho $，当 $ \rho $ 取到无穷大的时候，这一项基本等于0（但是，这样又回到了罚函数法的模式，当 $ \rho $ 太大的时候，Hessian条件数会变得很大，问题就会变得病态，求解速度会下降）
+ 不断更新 $ \bar\lambda=\lambda^*(\lambda) $，当Lagrange乘子满足$ \bar\lambda=\lambda^* $ 的时候，这一项基本等于0

**问题求解：**

上述问题可以进行分步求解，首先求解内层的优化问题： 

$ \max_\lambda f(x)+\lambda ^T h(x)−\frac{1}{2\rho}  \| \lambda - \bar{\lambda} \|^2 $

内层优化问题的最优解是：$  λ^∗(\bar\lambda)=\bar\lambda+\rho h(x) $，把 $ \lambda^* $ 最优解带入原始问题，得到如下优化问题：

$ \min_{x} \left( f(x) + \bar\lambda^T h(x) + \frac{1}{2} \rho \| h(x) \|^2 \right) $

上述优化问题是一个无约束优化问题，可以用之前介绍的无约束优化方法轻松求解，例如BFGS、牛顿法、梯度下降法等等。

总结一下，对于等式约束的增强拉格朗日方法的迭代求解过程： 

$ L(x,\lambda)=f(x)+\frac{1}{2}\rho\|h(x)+\frac{\lambda}{\rho}\|^2 
=f(x)+\lambda^Th(x)+\frac{1}{2}\rho\|h(x)\|^2+\frac{1}{2\rho}\|\lambda\|^2 \\
\left\{
\begin{aligned}
x_{k+1} &= \arg\min_xL(x_k,\lambda_k,\rho_k) \\
\lambda_{k+1} &= \lambda_k +\rho_kh(x_k+1) \\
\rho_{k+1} &= \min(\rho_k+\gamma\rho_k,\beta)
\end{aligned}
\right.
 $

其中， $ \gamma \leq 0 $代表的是 $ \rho $ 的放大系数，$  \beta > 0 $代表的是 $ \rho $ 的上限。注意到，上面的 $ L  $ 函数的形式和上推导的行驶略有不同，主要在于多了一项$ \frac{1}{2\rho}\|\lambda\|^2 $ ，这一项对于 $ x $ 的优化没有影响，所以可以对结果无影响。

**为什么叫增广拉格朗日方法：**

换一个视角， $ \min_{x} \left( f(x) + \bar\lambda^T h(x) - \frac{1}{2} \rho \| h(x) \|^2 \right) $可以看成是下面问题的Lagrange函数，即：

$ \begin{aligned}
    & \min_xf(x) + \frac{1}{2} \rho\|h(x)\|^2 \\
    & \text{s.t.} h(x)=0 \\
\end{aligned} $

这里面，当 $ x $ 满足约束时，上述问题和原问题是完全等价的，其中 $ \frac{1}{2} \rho\|h(x)\|^2  $ 就是所谓的增广项，这也是这个方法被称为增广拉格朗日算法的原因

## 4.2 不等式约束的处理
考虑一个具有不等式约束的优化问题，形式如下：

$ \begin{aligned}
    & \min_xf(x)\\
    & \text{s.t.} g(x) \leq 0 \\
\end{aligned} $

通过引入松弛变量，把不等式约束转换为等式约束： 

$ \begin{aligned}
    & \min_xf(x)\\
    & \text{s.t.} g(x) + s^2 = 0 \\
\end{aligned} $

于是，采用等式约束的增强拉格朗日方法，上述问题等价于：

$ \min_{x,s}f(x)+\frac{1}{2}\rho\|g(x)+s^2+ \frac{\mu}{\rho} \|^2 $

进一步针对上述优化问题进行讨论

+ 当 $ g(x)+\mu \rho >0 $ 时，要使得目标函数最小，$ s $ 应该取0。
+ 当 $ g(x)+\mu \rho < 0 $ 时，要使得目标函数最小， $ s^2=−[g(x)+\mu \rho] $ 。

所以，把最优的 s 取值带入，优化问题转换为了： 

$ \min_{x}f(x)+\frac{1}{2}\rho\|\max(g(x)+\frac{\mu}{\rho},0) \|^2 $

同时，最优的 s 取值带入Lagrange乘子的更新过程，可得：

$  \mu_{k+1}=\mu_k+\rho_k[g(x_{k+1})+s_{k+1}^2] = \max[\mu_k+\rho_k g(x_{k+1}, 0)] $

## 4.3 完整算法
对于含有等式约束和不等式约束的优化问题： 

$ \begin{aligned}
    & \min_xf(x)\\
    & \text{s.t.} h(x)=0 \\
    &~~~~~ g(x) \leq 0 \\
\end{aligned} $

总结一下，对于含有等式约束和不等式约束的增强拉格朗日方法的迭代求解过程： 

$ L(x,\lambda)=f(x)+\frac{1}{2}\rho\|h(x)+\frac{\lambda}{\rho}\|^2 + \frac{1}{2}\rho \| \max(g(x)+\frac{\mu}{\rho},0) \|^2 \\
\left\{
\begin{aligned}
x_{k+1} &= \arg\min_xL(x_k,\lambda_k,\rho_k) \\
\lambda_{k+1} &= \lambda_k +\rho_kh(x_{k+1}) \\
\mu_{k+1} &= \max(\mu_k+\rho_kg(x_{k+1}), 0) \\
\rho_{k+1} &= \min(\rho_k+\gamma\rho_k,\beta)
\end{aligned}
\right.
 $

其中， $ \gamma \leq 0 $ 代表的是 $ \rho $ 的放大系数， $ \beta $ 代表的是 $ \rho $ 的上限。

增广拉格朗日法的优化目标函数为：

$ \mathcal{L}(x, \lambda, \mu) = f(x) + \lambda^T h(x) + \frac{\rho}{2} \|h(x)\|^2 + \mu^T g(x) + \frac{\rho}{2} \|\max(0, g(x))\|^2 $

#  工程经验
为了确保数值计算的稳定性，可以通过目标函数缩放因子 `scale_fx` 和约束缩放因子 `scale_cx` 来调整目标函数和约束的权重，从而改善优化过程的表现。

+ **目标函数缩放因子 (**`**scale_fx**`**)**：当目标函数的梯度与约束的梯度存在量级差异时，使用 `scale_fx` 对目标函数的权重进行适当调整，可以有效缓解数值不稳定的问题，使优化算法更加稳健。
+ **约束缩放因子 (**`**scale_cx**`**)**：通过对等式和不等式约束的梯度进行归一化或重新加权，`scale_cx` 能避免约束之间因量级差异而导致的优化效率降低，从而提高约束处理的数值稳定性。



